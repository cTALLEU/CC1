---
title: "Tutoriel_Phyloseq"
output:
  github_document:
    toc: true
    toc_depth: 2
---

# Introduction.

## Installation des packages.

Tout les packages seront installés dans un script à part (00_package-install.Rmd). 
Il faut donc bien penser à les installer avant ou pendant la réalisation de ce tutoriel. 

## Importater les données.

Les données utilisées pour nos analyses ont été obtenue par Illumina Miseq 2x250 amplicon de la séquence V4 du 16S  (Kozich et al. 2013).
Ils proviennent de 360 échantillons fécaux collectés de 12 souries dans leur première année de vie afin d'étudier le développement et la stabilité du microbiome murin(Schloss et al. 2012).

L'importation des données sera réalisée dans un script à part (01_data-import.Rmd), ne pas oublier de le faire avant de continuer. 

On peut maintenant commencer. 


Après avoir dezippé les données, on va les associer à une variable. 

```{r}
miseq_path <- "./MiSeq_SOP" # CHANGE to the directory containing the fastq files after unzipping.
list.files(miseq_path)
```

# Filtration et réduction des données. 

Dans cette partie, nous allons retirer les reads de mauvaise qualité et réduire les autres pour qu'ils aient une longueur constante. 

Premièrement, on va lire les fichiers de fastq et créer des listes que l'on va associer à des variables:
-> Variable fnFs pour les fowards.
-> Variable fnRs pour les reverses.

```{r}
# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(miseq_path, pattern="_R1_001.fastq"))
fnRs <- sort(list.files(miseq_path, pattern="_R2_001.fastq"))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)
# Specify the full path to the fnFs and fnRs
fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)
fnFs[1:3]
```
```{r}
fnRs[1:3]
```

Quand on séquence en utilisant la méthode Illumina, il va y avoir une baisse de qualité à la fin du séquençage des reads
On peux voir cela sur les graphiques suivants (pour les deux premiers fowards et reverses):

```{r}
library(ggplot2)
library(dada2)
plotQualityProfile(fnFs[1:2])
```

On remarque une baisse du Qscore lors des cycles, mais c'est après 240 cycles que ce score va passer en dessous de 30 (valeur limite concensus)


```{r}
plotQualityProfile(fnRs[1:2])
```

Le Qscore des reverses baisse beaucoup plus rapidement que pour les fowards. Il passe en dessous de 30 après seulement 160 cycles. 


```{r}
filt_path <- file.path(miseq_path, "filtered") # Place filtered files in filtered/ subdirectory
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))
```

Quand on filtre et réduit (filter and trim), le foward et reverse associé doivent tous les deux passer la 'sélection' pour être gardé, si l'un ne passe pas, l'autre sera automatiqement éliminé.

Au vu des Qscores, on a choisi de troncater à la position 240 pour les fowards et 160 pour les reverses.

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

# En déduire les sequences de variants

Grâce à la méthode DADA2, on va former des ASVs (amplicon sequence variants) et non des OTU, ce qui permet de différentier des variants n'ayant qu'un seul nucléotide de différence par exemple. 

## Dereplication

On va determiner l'abondance de chaques séquences uniques 'combien de reads on la même séquences)

```{r}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames
```

méthode DADA2: pour différentier les variants et les erreurs de séquençage 

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

On va faire un graphe de ces erreurs estimées afin de les comparer avec le taux d'erreur ajusté et donc de savoir si nous avons correctement estimé ces ereurs. 

```{r}
plotErrors(errF)
plotErrors(errR)
```

```{r}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
```

On peut maintenant observer ce que DADA nous a retourné.

```{r}
dadaFs[[1]]
```
On va mettre ensemble les fowards avec leur reverses et retirer les paires qui ne sont pas parfaitement complémentaires pour éliminer les dernières erreurs. 

# Construction de la table de sequence et suppression des chimères.

## Construction de la table.

```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
```

```{r}
seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))])
table(nchar(getSequences(seqtabAll)))
```

Les chimères n'ont pas encore été retiré, c'est ce que l'on va faire ensuite. 

## Supression des chimères.

Comparaison de chaque séquences de la table entre-elles pour éliminer celles qui serai le résultat de deux autres plus abondante. 

```{r}
seqtabNoC <- removeBimeraDenovo(seqtabAll)
```


# Assignation de la taxonomie.

L'avantage d'utiliser le 16S de l'ADNr est qu'il permet de bien assigner les ASVs à un groupe taxonomique en comparant les séquences avec celles de bases de données (ici, on utilisera Silva)

```{r}
library(dada2)
fastaRef <- "~/silva_nr99_v138_train_set.fa.gz"
taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread=TRUE)
unname(head(taxTab))
```



#Construct phylogenetic tree

Grâce a l'assignation de la taxonomie, on peut maintenant construire un arbre phylogénétique. 

On va utiliser le package DECIPHER pour cela. 

```{r}
library(DECIPHER)
seqs <- getSequences(seqtabNoC)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
```

```{r}
library(phangorn)
library(ape)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```


# Combiner les données dnas un objet phyloseq

Cela va nous permettre de manipuler plus facilement ces données

```{r}
samdf <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/MIMARKS_Data_combined.csv",header=TRUE)
samdf$SampleID <- paste0(gsub("00", "", samdf$host_subject_id), "D", samdf$age-21)
samdf <- samdf[!duplicated(samdf$SampleID),] # Remove dupicate entries for reverse reads
rownames(seqtabAll) <- gsub("124", "125", rownames(seqtabAll)) # Fix discrepancy
all(rownames(seqtabAll) %in% samdf$SampleID) # TRUE
```

```{r}
rownames(samdf) <- samdf$SampleID
keep.cols <- c("collection_date", "biome", "target_gene", "target_subfragment",
"host_common_name", "host_subject_id", "age", "sex", "body_product", "tot_mass",
"diet", "family_relationship", "genotype", "SampleID") 
samdf <- samdf[rownames(seqtabAll), keep.cols]
```


```{r}
library(phyloseq)
ps <- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxTab),phy_tree(fitGTR$tree))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
ps
```


# Utilisation de phyloseq


## Chargement des données

ici, on importe l'object phyloseq ps

```{r}
ps_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds")
ps = readRDS(ps_connect)
ps
```

## Filtrage taxonomique

On va commencer par créer une table avec le nombre de reads pour chaque phylum représenté dans nos données. 

```{r}
# Show available ranks in the dataset
rank_names(ps)
```
```{r}
# Create table, number of features for each phyla
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```

On retire les phyla qui n'ont pas de représentant dans nos données. On remarque que certains phyla ne sont représentés que par un représentant. 

```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```

On peut determiner la prévalence, c'est a dire le nombre d'échantillons de chaque taxon qui apparait au moins une fois. 

```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```

On peut déterminer donc la prévalence et la prévalence moyenne pour chaque phylum. 

```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

il n'y a que deux échantillons représentant les Fusobacteria dans nos données. Le phylum Deinococcus-Thermus ne represente lui que 1% des échantillons. 
On va les retirer des données (abondance considérée comme trop faible pour les garder dnas la suite de notre étude). 


```{r}
# Define phyla to filter
filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```



## Filtrage de la prévalence

Dans certains cas, les données que l'on hésitait à éliminer peuvent s'avérer utile, il faut donc bien choisir. 


```{r}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```
On utiliser ces graphes afin de determiner les paramètres de filtration (souvent, on determine comme critère un niveau minimal de la prévalence)

On va utiliser 5% de tous les echantillons comme seuil de la prévalence.
```{r}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```

```{r}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)

```



## Agglomération de taxa  

determination de taxa très rapproché grace a la redondance des fonctions qu'ils peuvent avoir. 

```{r}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```
```{r}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```

On va utiliser la taille des branches de l'arbre pour connaitre la distance phylogénétiques entre les fonctions. C'est similaire au clustering des OTU mais en y integrant une notion d'évolution. 

```{r}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```


```{r}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
```


```{r}
library(gridExtra)
# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```
On voit bien ici l'effet de l'agglomération sur la forme de l'arbre

## Transformation de la valeur de l'abondance. 

On va pouvoir comparer la distribution des valeurs de l'abondance de l'objet phyloseq avant et après transformation. 

```{r}
plot_abundance = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "sex",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```


```{r}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```

On peut faire une visualisation avant/après des valeurs de l'abondance. 
```{r}
plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 2,  plotBefore, plotAfter)
```
On a ici une cmparaison de l'abondance originelle et de la relative. 

## Créations de sous-ensembles grâce à la taxonomie. 


```{r}
psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```
distribution bimodale pour Lactobacillus. 

Installations de packages pour faire des analyses complémentaires (voir partie analyses complémentaires dans le script 00_package-install)


# Prétraitement

On ajoute des colonnes aux échantillons de nos données afin d'annoter nos visualisations. 
On détermine des souris jeunes, agées ou d'âge moyen, ainsi que le nombre total de chaque. 
On va transformer en log les données pour une stabilisation approximale de la variance. 


```{r}
qplot(sample_data(ps)$age, geom = "histogram",binwidth=20) + xlab("age")

```
On voit 3 groupes bien séparés en fonction de l'âge. 

```{r}
qplot(log10(rowSums(otu_table(ps))),binwidth=0.2) +
  xlab("Logged counts-per-sample")
```


On va faire une PCoA et utiliser un indice de dissimilarité de Bray-Curtis

```{r}
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship=gsub(" ","",sample_data(ps)$family_relationship)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned") +
  labs(col = "Binned Age") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Analyse des ordinations avec le log des abondances. 


```{r}
rel_abund <- t(apply(otu_table(ps), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram",binwidth=0.05) +
  xlab("Relative abundance")
```
Il y a une réelle dominance d'une ASV


# Projection de différentes ordinations. 



```{r}
outliers <- c("F5D165", "F6D165", "M3D175", "M4D175", "M5D175", "M6D175")
ps <- prune_samples(!(sample_names(ps) %in% outliers), ps)
```

On retire les echantillons représentés par  moins de 1000 reads
```{r}
which(!rowSums(otu_table(ps)) > 1000)
```
```{r}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```

On va faire une PCoA et utiliser un indice de dissimilarité de Bray-Curtis

```{r}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "age_binned",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Visualisation de la PCoA en utilisant Bray-Curtis

On utilise maintenant la méthode de DPCoA , elle va donner une double visualisation des échantillons et des catégories taxonomiques. 
On a vu dnas le graphe précédant une distinction dasn la distribution entre les sujets jeunes ou âgés

```{r}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "age_binned", label= "SampleID",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```

```{r}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```

On va maitenant regarder les résultats de la PCoA en utilisant Unifract

```{r}
out.wuf.log <- ordinate(pslog, method = "PCoA", distance ="wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned",
                  shape = "family_relationship") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  labs(col = "Binned Age", shape = "Litter")
```

## PCA on ranks


```{r}
abund <- otu_table(pslog)
abund_ranks <- t(apply(abund, 1, rank))
```

```{r}
abund_ranks <- abund_ranks - 329
abund_ranks[abund_ranks < 1] <- 1
```

A cause des bactéries absente ou présente sos forme de trace, on peut avoir une grande différence des rangs crée artificiellement. 
On va donc donner le rang 1 a celles trop bas, et les autres abaissés pour que l'écart entre les rang ne soit pas trop important. 

```{r}
library(dplyr)
library(reshape2)
abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

sample_ix <- sample(1:nrow(abund_df), 8)
ggplot(abund_df %>%
         filter(sample %in% abund_df$sample[sample_ix])) +
  geom_point(aes(x = abund, y = rank, col = sample),
             position = position_jitter(width = 0.2), size = 1.5) +
  labs(x = "Abundance", y = "Thresholded rank") +
  scale_color_brewer(palette = "Set2")
```
association entre rang et abondance pour des échantillons pris aléatoirement. les nombres de l'axe des Y sont ceux pour la PCoA

On peut donc maintenant faire une PCoA

```{r}
library(ade4)
ranks_pca <- dudi.pca(abund_ranks, scannf = F, nf = 3)
row_scores <- data.frame(li = ranks_pca$li,
                         SampleID = rownames(abund_ranks))
col_scores <- data.frame(co = ranks_pca$co,
                         seq = colnames(abund_ranks))
tax <- tax_table(ps) %>%
  data.frame(stringsAsFactors = FALSE)
tax$seq <- rownames(tax)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
tax$otu_id <- seq_len(ncol(otu_table(ps)))
row_scores <- row_scores %>%
  left_join(sample_data(pslog))
col_scores <- col_scores %>%
  left_join(tax)
```

```{r}
evals_prop <- 100 * (ranks_pca$eig / sum(ranks_pca$eig))
ggplot() +
  geom_point(data = row_scores, aes(x = li.Axis1, y = li.Axis2), shape = 2) +
  geom_point(data = col_scores, aes(x = 25 * co.Comp1, y = 25 * co.Comp2, col = Order),
             size = .3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  facet_grid(~ age_binned) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
       y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  coord_fixed(sqrt(ranks_pca$eig[2] / ranks_pca$eig[1])) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
graphe résulte d'une analyse PCoA après une transofrmation par troncaténation des rangs

il reste similaire au précédant (sans la transofrmation) -> Cela nous conforte dnas l'idée que l'analyse de nos données était bonne. 
## Canonical correspondence

la CCpnA (canonical correspondence analysis) est une approche pour faire des ordinations d'espèces par des tables d'échantillonnages. Cela donne des informations supplémentaire par rapport à avant. 

Cela permet de créer des biplot où la position des échantillons sont determinés par des signatures spécifiques et des charactéristiques environnementales. 

On dois fournir un argument supplémentaire par rapport à la PCoA ou DPCoA, sinon il va utiliser toutes les mesures quand il ferra l'ordination. 

```{r}
ps_ccpna <- ordinate(pslog, "CCA", formula = pslog ~ age_binned + family_relationship)
```
On annote les 4 ordre taxonomiques les plus important. 
```{r}
library(ggrepel)
ps_scores <- vegan::scores(ps_ccpna)
sites <- data.frame(ps_scores$sites)
sites$SampleID <- rownames(sites)
sites <- sites %>%
  left_join(sample_data(ps))

species <- data.frame(ps_scores$species)
species$otu_id <- seq_along(colnames(otu_table(ps)))
species <- species %>%
  left_join(tax)
evals_prop <- 100 * ps_ccpna$CCA$eig[1:2] / sum(ps_ccpna$CA$eig)
ggplot() +
  geom_point(data = sites, aes(x = CCA1, y = CCA2), shape = 2, alpha = 0.5) +
  geom_point(data = species, aes(x = CCA1, y = CCA2, col = Order), size = 0.5) +
  geom_text_repel(data = species %>% filter(CCA2 < -2),
                    aes(x = CCA1, y = CCA2, label = otu_id),
            size = 1.5, segment.size = 0.1) +
  facet_grid(. ~ family_relationship) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
        y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  scale_color_brewer(palette = "Set2") +
  coord_fixed(sqrt(ps_ccpna$CCA$eig[2] / ps_ccpna$CCA$eig[1])*0.45   ) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
Score des bactéries et des souris généré par CCpnA

# Enseignement supervisé

On va utiliser des méthodes qui fonctionne bien sur R

On va utiliser dans un premier temps PLS
```{r}
library(caret)
library(lattice)
sample_data(pslog)$age2 <- cut(sample_data(pslog)$age, c(0, 100, 400))
dataMatrix <- data.frame(age = sample_data(pslog)$age2, otu_table(pslog))
# take 8 mice at random to be the training set, and the remaining 4 the test set
trainingMice <- sample(unique(sample_data(pslog)$host_subject_id), size = 8)
inTrain <- which(sample_data(pslog)$host_subject_id %in% trainingMice)
training <- dataMatrix[inTrain,]
testing <- dataMatrix[-inTrain,]
plsFit <- train(age ~ ., data = training,
                method = "pls", preProc = "center")
```
On peut prédir l'age.
```{r}
plsClasses <- predict(plsFit, newdata = testing)
table(plsClasses, testing$age)
```

On peut utiliser les random forest.
```{r}
library(randomForest)
rfFit <- train(age ~ ., data = training, method = "rf",
               preProc = "center", proximity = TRUE)
rfClasses <- predict(rfFit, newdata = testing)
table(rfClasses, testing$age)
```
To interpret these PLS and random forest results, it is standard to produce biplots and proximity plots, respectively. The code below extracts coordinates and supplies annotation for points to include on the PLS biplot.

Remarque: installation de vegan dnas les install_packages 

```{r}
library(vegan)
pls_biplot <- list("loadings" = loadings(plsFit$finalModel),
                   "scores" = scores(plsFit$finalModel))
class(pls_biplot$scores) <- "matrix"

pls_biplot$scores <- data.frame(sample_data(pslog)[inTrain, ],
                                pls_biplot$scores)

tax <- tax_table(ps)@.Data %>%
  data.frame(stringsAsFactors = FALSE)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
class(pls_biplot$loadings) <- "matrix"
pls_biplot$loadings <- data.frame(tax, pls_biplot$loadings)
```

```{r}
ggplot() +
  geom_point(data = pls_biplot$scores,
             aes(x = Comp.1, y = Comp.2), shape = 2) +
  geom_point(data = pls_biplot$loadings,
             aes(x = 25 * Comp.1, y = 25 * Comp.2, col = Order),
             size = 0.3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Axis1", y = "Axis2", col = "Binned Age") +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  facet_grid( ~ age2) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
```
The resulting biplot is displayed in Figure 17; it can be interpreted similarly to earlier ordination diagrams, with the exception that the projection is chosen with an explicit reference to the binned age variable. Specifically, PLS identifies a subspace to maximize discrimination between classes, and the biplot displays sample projections and ASV coefficients with respect to this subspace.

```{r}
rf_prox <- cmdscale(1 - rfFit$finalModel$proximity) %>%
  data.frame(sample_data(pslog)[inTrain, ])

ggplot(rf_prox) +
  geom_point(aes(x = X1, y = X2, col = age_binned),
             size = 1, alpha = 0.7) +
  scale_color_manual(values = c("#A66EB8", "#238DB5", "#748B4F")) +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  labs(col = "Binned Age", x = "Axis1", y = "Axis2")
```
determination de la distance entre les échantillons grâce a un modèle de random forest. On peut y associer un PCoA. 

Si des échantillons sont souvent dans une même partitions, alor la distance les séparant sera plus faible que si ce n'était pas le cas. 


```{r}
as.vector(tax_table(ps)[which.max(importance(rfFit$finalModel)), c("Family", "Genus")])
```
```{r}
impOtu <- as.vector(otu_table(pslog)[,which.max(importance(rfFit$finalModel))])
maxImpDF <- data.frame(sample_data(pslog), abund = impOtu)
ggplot(maxImpDF) +   geom_histogram(aes(x = abund)) +
  facet_grid(age2 ~ .) +
  labs(x = "Abundance of discriminative bacteria", y = "Number of samples")
```
identification du microbe avec le plus d'influence sur les prédictions du random forest
Il appartient à la famille des Lachnospiraceae et du genre Roseburia. 

# Analyses basées sur des graphes


## Création et visualisation de graphes

cela est possible grâce à phyloseq


```{r}
library("phyloseqGraphTest")
library("igraph")
library("ggnetwork")

net <- make_network(ps, max.dist=0.35)
sampledata <- data.frame(sample_data(ps))
V(net)$id <- sampledata[names(V(net)), "host_subject_id"]
V(net)$litter <- sampledata[names(V(net)), "family_relationship"]

net_graph <- ggnetwork(net)
```


```{r}
ggplot(net_graph, aes(x = x, y = y, xend = xend, yend = yend), layout = "fruchtermanreingold") +
  geom_edges(color = "darkgray") +
  geom_nodes(aes(color = id, shape = litter),  size = 3 ) +
  theme(axis.text = element_blank(), axis.title = element_blank(),
        legend.key.height = unit(0.5,"line")) +
  guides(col = guide_legend(override.aes = list(size = .5)))
```
basé sur une matrice de dissimilarité de Jaccard
Les couleurs corresponde à l'origine des échantillons (quelle souris)
On voit des regroupements en fonction des souris d'origine et la litère. 

# Graph-based two-sample tests

## Minimum Spanning Tree (MST)

on va utiliser un indice de dissimilarité de Jaccard


```{r}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "mst")
gt$pval
```
pourquoi la valeur précédente n'est pas la même que dans le tuto .... 


```{r}
plotNet1=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm1=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet1, plotPerm1)
```
Ici, rejet de l'hypothèse nulle que deux échantillons sont issus de la même distribution.
On voit aussi une répartition en groupe. 
## Voisins les plus proches

```{r}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "knn", knn = 1)
```

```{r}
plotNet2=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm2=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet2, plotPerm2)
```
On voit sur ce graphe les voisins les plus proches

## Modélisations linéaires

On calcule l'indice de diversité de Shannon de chaque échantillons et on ajoute des annotations

```{r}
library("nlme")
library("reshape2")
library("dplyr")
ps_alpha_div <- estimate_richness(ps, split = TRUE, measure = "Shannon")
ps_alpha_div$SampleID <- rownames(ps_alpha_div) %>%
  as.factor()
ps_samp <- sample_data(ps) %>%
  unclass() %>%
  data.frame() %>%
  left_join(ps_alpha_div, by = "SampleID") %>%
  melt(measure.vars = "Shannon",
       variable.name = "diversity_measure",
       value.name = "alpha_diversity")

# reorder's facet from lowest to highest diversity
diversity_means <- ps_samp %>%
  group_by(host_subject_id) %>%
  summarise(mean_div = mean(alpha_diversity)) %>%
  arrange(mean_div)
ps_samp$host_subject_id <- factor(ps_samp$host_subject_id)
#                                  diversity_means$host_subject_id)
```


```{r}
alpha_div_model <- lme(fixed = alpha_diversity ~ age_binned, data = ps_samp,
                       random = ~ 1 | host_subject_id)
```


```{r}
new_data <- expand.grid(host_subject_id = levels(ps_samp$host_subject_id),
                        age_binned = levels(ps_samp$age_binned))
new_data$pred <- predict(alpha_div_model, newdata = new_data)
X <- model.matrix(eval(eval(alpha_div_model$call$fixed)[-2]),
                  new_data[-ncol(new_data)])
pred_var_fixed <- diag(X %*% alpha_div_model$varFix %*% t(X))
new_data$pred_var <- pred_var_fixed + alpha_div_model$sigma ^ 2
```

```{r}
# fitted values, with error bars
ggplot(ps_samp %>% left_join(new_data)) +
  geom_errorbar(aes(x = age_binned, ymin = pred - 2 * sqrt(pred_var),
                    ymax = pred + 2 * sqrt(pred_var)),
                col = "#858585", size = .1) +
  geom_point(aes(x = age_binned, y = alpha_diversity,
                 col = family_relationship), size = 0.8) +
  facet_wrap(~host_subject_id) +
  scale_y_continuous(limits = c(2.4, 4.6), breaks = seq(0, 5, .5)) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Binned Age", y = "Shannon Diversity", color = "Litter") +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)),
        axis.text.x = element_text(angle = -90, size = 6),
        axis.text.y = element_text(size = 6))
```


# Tests multiples hiérarchisés. 

installation de DESeq2 dnas package install 

```{r}
library("reshape2")
library("DESeq2")
#New version of DESeq2 needs special levels
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship = gsub(" ", "", sample_data(ps)$family_relationship)
ps_dds <- phyloseq_to_deseq2(ps, design = ~ age_binned + family_relationship)

# geometric mean, set to zero when all coordinates are zero
geo_mean_protected <- function(x) {
  if (all(x == 0)) {
    return (0)
  }
  exp(mean(log(x[x != 0])))
}

geoMeans <- apply(counts(ps_dds), 1, geo_mean_protected)
ps_dds <- estimateSizeFactors(ps_dds, geoMeans = geoMeans)
ps_dds <- estimateDispersions(ps_dds)
abund <- getVarianceStabilizedData(ps_dds)
```

Tests hiérarchisés. 

Racourcir les noms de chaques taxa/ASVs
```{r}
short_names <- substr(rownames(abund), 1, 5)%>%
  make.names(unique = TRUE)
rownames(abund) <- short_names
```

```{r}
abund_sums <- rbind(data.frame(sum = colSums(abund),
                               sample = colnames(abund),
                               type = "DESeq2"),
                    data.frame(sum = rowSums(otu_table(pslog)),
                               sample = rownames(otu_table(pslog)),
                               type = "log(1 + x)"))

ggplot(abund_sums) +
  geom_histogram(aes(x = sum), binwidth = 20) +
  facet_grid(type ~ .) +
  xlab("Total abundance within sample")
```
Graphe du haut: abondance transformée DESeq2 de chaque échatillons
Graphe du bas : idem mais inclu des comparaisons

Détermination de noeud des racines (et donc relations "parents/enfants). 

```{r}
library("structSSI")
el <- phy_tree(pslog)$edge
el0 <- el
el0 <- el0[nrow(el):1, ]
el_names <- c(short_names, seq_len(phy_tree(pslog)$Nnode))
el[, 1] <- el_names[el0[, 1]]
el[, 2] <- el_names[as.numeric(el0[, 2])]
unadj_p <- treePValues(el, abund, sample_data(pslog)$age_binned)
```

On peut corriger la p-valeur en utilisant une procedure de hiérarchisation afin de garantir le contrôle des variants du contrôle FDR. 

```{r}
hfdr_res <- hFDR.adjust(unadj_p, el, .75)
summary(hfdr_res)
```


```{r echo=FALSE, results='hide',message=FALSE}
#interactive part: not run
plot(hfdr_res, height = 5000) # opens in a browser
```

```{r}
tax <- tax_table(pslog)[, c("Family", "Genus")] %>%
  data.frame()
tax$seq <- short_names
```


```{r}
options(digits=3)
hfdr_res@p.vals$seq <- rownames(hfdr_res@p.vals)
tax %>%
  left_join(hfdr_res@p.vals) %>%
  arrange(adjp) %>% head(10)
```
La majorité des bactéries sont associées a la famille des Lachnospiraceae. Cela concorde avec les résultats du random forest. 

# Techniques multitables. 

sparse CCA , méthode utile dnas la comparaison entre échantillons et identifications de fonction avec des variations interessantes. 

import de deux tables: une pour les bactéries et une pour les métabolites. On va avoir 12 echantillons contenant 20609 OTUs et 637 m/z valeurs

Remarque: 96% d'entre eux ont une abondance de zéro, on les filtrera après. 

```{r}
metab <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/metabolites.csv",row.names = 1)
microbe_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/microbe.rda")
load(microbe_connect)
microbe
```
On filtre les microbes et métabolite en éliminant ceux qui ont une valeur de 0
On va faire le log des métabolites

```{r}
library("genefilter")
keep_ix <- rowSums(metab == 0) <= 3
metab <- metab[keep_ix, ]
microbe <- prune_taxa(taxa_sums(microbe) > 4, microbe)
microbe <- filter_taxa(microbe, filterfun(kOverA(3, 2)), TRUE)
metab <- log(1 + metab, base = 10)
X <- otu_table(microbe)
X[X > 50] <- 50
dim(X)
```
```{r}
dim(metab)
```

```{r}
library(PMA)
cca_res <- CCA(t(X),  t(metab), penaltyx = .15, penaltyz = .15)
```

```{r}
cca_res
```
On sélection 5 microbe et 15 métabolites

On fait maintenant une PCA ordinaire. 


```{r}
combined <- cbind(t(X[cca_res$u != 0, ]),
                  t(metab[cca_res$v != 0, ]))
pca_res <- dudi.pca(combined, scannf = F, nf = 3)
```


```{r}
genotype <- substr(rownames(pca_res$li), 1, 2)
sample_type <- substr(rownames(pca_res$l1), 3, 4)
feature_type <- grepl("\\.", colnames(combined))
feature_type <- ifelse(feature_type, "Metabolite", "OTU")
sample_info <- data.frame(pca_res$li, genotype, sample_type)
feature_info <- data.frame(pca_res$c1,
                           feature = substr(colnames(combined), 1, 6))
```


```{r}
ggplot() +  geom_point(data = sample_info,
            aes(x = Axis1, y = Axis2, col = sample_type, shape = genotype), size = 3) + 
  geom_label_repel(data = feature_info,
                   aes(x = 5.5 * CS1, y = 5.5 * CS2, label = feature, fill = feature_type),
                   size = 2, segment.size = 0.3,
                   label.padding = unit(0.1, "lines"), label.size = 0) +
  geom_point(data = feature_info,
             aes(x = 5.5 * CS1, y = 5.5 * CS2, fill = feature_type),
             size = 1, shape = 23, col = "#383838") +
  scale_color_brewer(palette = "Set2") +
  scale_fill_manual(values = c("#a6d854", "#e78ac3")) +
  guides(fill = guide_legend(override.aes = list(shape = 32, size = 0))) +
  coord_fixed(sqrt(pca_res$eig[2] / pca_res$eig[2])) +
  labs(x = sprintf("Axis1 [%s%% Variance]",
                   100 * round(pca_res$eig[1] / sum(pca_res$eig), 2)),
       y = sprintf("Axis2 [%s%% Variance]",
                   100 * round(pca_res$eig[2] / sum(pca_res$eig), 2)),
       fill = "Feature Type", col = "Sample Type")
```
PCA triplot
